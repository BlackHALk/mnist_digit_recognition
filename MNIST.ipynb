{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"C:/Users/User/Desktop/mnist\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x00000256279A5898>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000002562790DE48>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000002562790DE10>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mnist.train.images\n",
    "labels = mnist.train.labels\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch = mnist.train.images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotData = batch[0]\n",
    "plotData = plotData.reshape(28, 28)\n",
    "plt.gray() # use this line if you don't want to see it in color\n",
    "plt.imshow(plotData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_steps = 1000\n",
    "batch_size = 32\n",
    "display_steps = 50\n",
    "\n",
    "#Network parameters\n",
    "\n",
    "num_input = 784 # (img shape : 28 * 28)\n",
    "num_classes = 10 #(0-9 digits)\n",
    "dropout = 0.75\n",
    "\n",
    "# tf graph input \n",
    "X = tf.placeholder(tf.float32, [None, num_input])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper for simplicity\n",
    "def conv2d(x, W, b, strides = 1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    \n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    # Maxpooling\n",
    "    \n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout): \n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "    \n",
    "    #conv layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max pooling\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    \n",
    "    #conv layer2\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max pooling\n",
    "    conv2 = maxpool2d(conv1, k=2)\n",
    "    \n",
    "    # Full connected layer \n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    # Applying Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    # Output class predction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing layers, weights and bias\n",
    "\n",
    "weights = {\n",
    "    # 5 x 5 conv, 1 input, 32 output\n",
    "    'wc1' : tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2' : tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # Fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1' : tf.Variable(tf.random_normal([7*7*32, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out' : tf.Variable(tf.random_normal([1024, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1' : tf.Variable(tf.random_normal([32])),\n",
    "    'bc2' : tf.Variable(tf.random_normal([64])),\n",
    "    'bd1' : tf.Variable(tf.random_normal([1024])),\n",
    "    'out' : tf.Variable(tf.random_normal([num_classes])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Model\n",
    "logits = conv_net(X, weights, biases, keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Calc loss and optimization\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Eval model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 2870.6765, Training Accuracy= 0.125\n",
      "Step 50, Minibatch Loss= 328.0525, Training Accuracy= 0.500\n",
      "Step 100, Minibatch Loss= 40.5061, Training Accuracy= 0.906\n",
      "Step 150, Minibatch Loss= 91.7284, Training Accuracy= 0.844\n",
      "Step 200, Minibatch Loss= 62.3163, Training Accuracy= 0.844\n",
      "Step 250, Minibatch Loss= 87.7057, Training Accuracy= 0.875\n",
      "Step 300, Minibatch Loss= 80.8447, Training Accuracy= 0.844\n",
      "Step 350, Minibatch Loss= 36.8112, Training Accuracy= 0.906\n",
      "Step 400, Minibatch Loss= 95.2685, Training Accuracy= 0.938\n",
      "Step 450, Minibatch Loss= 148.9629, Training Accuracy= 0.875\n",
      "Step 500, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 550, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 600, Minibatch Loss= 22.8998, Training Accuracy= 0.938\n",
      "Step 650, Minibatch Loss= 30.1406, Training Accuracy= 0.969\n",
      "Step 700, Minibatch Loss= 51.1384, Training Accuracy= 0.938\n",
      "Step 750, Minibatch Loss= 88.5917, Training Accuracy= 0.906\n",
      "Step 800, Minibatch Loss= 105.0775, Training Accuracy= 0.906\n",
      "Step 850, Minibatch Loss= 88.3522, Training Accuracy= 0.875\n",
      "Step 900, Minibatch Loss= 38.5469, Training Accuracy= 0.906\n",
      "Step 950, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 1000, Minibatch Loss= 62.1879, Training Accuracy= 0.875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.9386\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "# Run the initializer\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    dict_value = {}\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n",
    "        if step % display_steps == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y,\n",
    "                                                                 keep_prob: 1.0})\n",
    "            dict_value[step] = acc\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: mnist.test.images,\n",
    "                                      Y: mnist.test.labels,\n",
    "                                      keep_prob: 1.0}))\n",
    "\n",
    "    \n",
    "    saver.save(sess, './my_mnist_model.ckpt',global_step=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model.ckpt-1000\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "def pred():\n",
    "    from PIL import Image\n",
    "    import PIL.ImageOps\n",
    "    from scipy.misc import imresize\n",
    "    import numpy as np\n",
    "    img = Image.open('img.jpg')\n",
    "\n",
    "    im = PIL.ImageOps.invert(img)\n",
    "    im = imresize(im,(28,28))\n",
    "    im = np.mean(im, axis = 2)\n",
    "    return im\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./my_mnist_model.ckpt-1000')\n",
    "    im = pred()\n",
    "    print(sess.run(prediction, feed_dict = {X:im.reshape(1,-1), keep_prob:1.0}))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2562ca4d9e8>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pred():\n",
    "    from PIL import Image\n",
    "    import PIL.ImageOps\n",
    "    from scipy.misc import imresize\n",
    "    import numpy as np\n",
    "    img = Image.open('img.jpg')\n",
    "\n",
    "    im = PIL.ImageOps.invert(img)\n",
    "    im = imresize(im,(28,28))\n",
    "    im = np.mean(im, axis = 2)\n",
    "    return im\n",
    "im = pred()\n",
    "plt.imshow(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(accuracy, feed_dict={X:im.reshape(1,-1),\n",
    "                                  Y: mnist.test.labels,\n",
    "                                  keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    sess.run(accuracy, feed_dict={X: mnist.test.images,\n",
    "                                  Y: mnist.test.labels,\n",
    "                                  keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = sorted(dict_value.items()) # sorted by key, return a list of tuples\n",
    "\n",
    "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
